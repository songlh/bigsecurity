\section{Malware Classification}
\label{sec:ssdeep}

Machine learning systems are just as good
as the data they consumed---One potential 
use case of the massive amount of data 
available on VirusTotal is to build 
machine learning models for applications
such as malware classifications and
clustering. In this section, we study
the question that {\em Is the data
provided by VirusTotal enough to support
classifications and clusterings tasks?}

Our study reveals both positive and
negative answers to this question---For
some classification tasks, we are able
to build an automatic classifier whose
accuracy is higher than 80\% by just
using the static signature provided by VirusTotal
and we expect the quality to keep increasing
given more data; on the other hand,
we identify some classification tasks
whose accuracy hardly beat random guesses.
We also identify a simple metrics
to predict whether a given task belongs
the high-quality category or the low-quality
category. We hope our study shed lights
on future design of signatures for malware
detection.

%Malware detectors mainly rely on signatures manually extracted by security researchers. 
%ssdeep only takes static binary executable as inputs. 
%If we can build malware detector based on ssdeep similarity, 
%We can reduce or even eliminate manual efforts in malware detection. 


\subsection{Data Collection}

\input{section/tbl_svm}

Our study uses features based on ssdeep~\cite{ssdeep}, a program to compute fuzzy hashes. 
Similarity between calculated hash strings can serve as an estimation for similarity between the two original files. 
ssdeep hash strings are also provided for each submitted file with other metadata fields by \vt. 

We focus on classifying each malware into
different malware families. Because Microsoft 
has a good reputation in detecting PE malwares~\cite{SongAPsys2016}, we create training
data using its assignment. For each detected malware, Microsoft assigns it a tag, which contains type, platform, family, and variant information~\cite{microsoft}. 
We divide PE malwares detected by Microsoft engine into different groups, and malwares in the same group share the same Microsoft malware tag. 
We sample 10 groups, each of which with more than 10000 malwares.  
Microsoft tag and number of malwares in each sampled group we collected from \vt{} are shown in Table~\ref{tab:benchmark}. 
For each group, we sample 10000 malwares, and use these malwares in our following experiments. 


\subsection{Classification Accuracy}

We build an classifier as follows. \ce{XXXX LINHAI, ADD IN THE PROTOCOL.}

Table~\ref{tab:results} shows the classification
result and Figure~\ref{fig:moredata} shows
the relationship between the amount of
training data and the accuracy of classifiers. 
We see that for five out of ten 
malware families, we achieve an accuracy
higher than 80\%. Moreover, as indicated
by Figure~\ref{fig:moredata}, when more
training data are available for these
families, we expect the accuracy to be even
higher. On the other hand, for
families such as ``Virus:Win32/Nabucur.D'',
the classification accuracy are significant
lower. We get an accuracy of 59\% when
\ce{the accuracy of random guesses would be 50\%. LINHAI IS THIS RIGHT?}
\ce{LINHAI, ADD ONE SENTENCE ABOUT THE REASON.}

\paragraph*{Discussion: Tailing Malwares}

We identify one metrics to predict whether
a classification task falls into the
high-accuracy category or low-accuracy
category. The intuition is that the probability
that a given sample has similar samples in
the training set is a proxy of the upper bound
of accuracy that we can expect. Therefore,
we compute the percentage of tailing malwares in each group--We call malwares, which have 0 similarity with all the other samples in the same group, as tailing malwares. 
The percentage of tailing malwares for each sampled group is also shown in Table~\ref{tab:benchmark}. 

\ce{LINHAI, ADD IN THAT \#TRAILING-VS.ACCURACY FIGURE AND ARGUE ABOUT CORRELATION HERE.}

\paragraph*{Discussion: Challenge of Applying Nystrom Methods for Kernel Machines}

\input{section/tbl_svm2}

Our previous experiment uses k-means classifier.
In this section, we discuss the potential of using
more sophisticated classifiers such as
support vector machines. One challenge
of applying kernel machines is to
approximate the kernel matrix whose
size is quadratic to the number of samples
in the training set. Nystrom Methods~\cite{clustering-purpose} are popular ways to
approximate a kernel matrix with clusters.

To understand the potential of applying Nystrom Methods, we run hierarchical clustering~\cite{hcluster} on our data.
Hierarchical clustering starts with each instance as a cluster, 
and then it iteratively merge two clusters with minimum distance 
until distance threshold or cluster number threshold is reached. 
We use distance as threshold. 
Given two malwares, 
we use 1 to minus their ssdeep similarity to calculate distance between the two malwares. 
We calculate single linkage distance as distance between two clusters. 
Single linkage
distance~\cite{single-link} when we need to compute distance between two clusters. 

We change distance threshold from 0.1 to 0.9, 
and count resulting clusters under each experiment. 
Experimental results are shown in Table~\ref{tab:results}. 
As we increase distance threshold, the number of resulting clusters decreases for each sampled group. 
The number of resulting clusters is always bounded by the number of tailing in each group. 
If we want to change a ssdeep hash string to a feature vector, 
based on distance of the string to the center of all clusters in training set, 
the size of the resulting feature vector would have a very large variance across different malware groups. 
\ce{This illustrates a challenge of directly applying
classic Nystrom method, however, we believe
it is possible to develop new approaches to
accommodate this observation in the future.}

\input{section/fig_MoreData}

%\subsection{Classification Experiments}


\subsection{Discussion}
1. Future work about indexing ssdeep string
2. Upper bound
3. More data better results
4. Need human effort or dynamic information 