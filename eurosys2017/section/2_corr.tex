\section{Correlation between Submission Properties and Detection Rate}
\label{sec:corr}
This section presents our study of the correlation between various properties of \pe\ submissions and the detection rate of \pe\ submissions.
Detection rate is what most \vt\ users use to decide if their submissions are malware 
and the first thing that a user of \vt\ uses.
Therefore, it is important to study what factors affects or correlates to detection rate
and the results can guide security researchers and vendors to invest XXX

We studied a range of properties and their correlation with detection rate
and found that ** factors have higher correlation:
the correlation between detection rate and submission file size,
historical submission properties, and the reputation and type of source IDs.
We present these correlation study results in this section.
In the next section, we will present our further analysis of what can affect the detection result of anti-virus engines
and if detection rate is a perfect measurement of the likelihood of malware.
%Detection rate is a good indication of the likelihood of malware.
%A higher detection rate means that more anti-virus engines identify a submitted file as malicious.
%\yiying{Can we say that higher detection rate indicates that the file is likely to be a malware?}
%Our study is conducted from four aspects: reputation of source id, submission history, 
%file size, and source country.

\input{section/fig_2corr1}

\subsection{File Size}
\label{sec:size}
Anecdotely, \pe\ malwares are most likely to have small to medium size. 
To verify this, we analyzed the relationship between submission file size and detection rate. 
Figure~\ref{fig:size} present the average detection rate and 95\% confidence interval for each preprocessed 
For each submission, we round up binary logarithm for its file size to nearest 0.5,
and calculate average detection rate for submissions with the same preprocessed file size.
file size.
\yiying{what do you mean by preprocessed file size? Also, change the X axis lables of this figure and figure 3 to be 1KB, 1MB, 1GB}
Except for the last two points, all other confidence intervals are invisible.   
\yiying{what do you mean by invisible?}
Files with size from 90KB to 4MB have higher detection rate, more than 20\% on average. 

{\bf Observation 4:} 
{\em \pe\ malwares are mostly likely to have small to medium size.}

Figure~\ref{fig_pesize}
One likely reason of this correlation is that  
\yiying{how is this result relates to the size distribution of files? 
what does it this result imply? any suspected reason behind this? My suspition is just that these sizes have more submissions and thus? has higher detection rate.}

\if 0
\subsection{Source Country}
\label{sec:country}

All PE submissions in our collection are conducted from 222 countries, 
and for roughly 17\% PE submissions, 
VirusTotal fails to provide their source country information. 
We rank source countries, based on their submission numbers. 
Average detection rate for top 20 source countries are calculated and shown in 
Figure~\ref{fig:Country}. 
Confidence intervals are also drawn for each source country, 
and all confidence intervals are almost invisible. 
From Figure~\ref{fig:Country}, 
we can see that submissions source countries are correlated with detection rate.
\yiying{What's the order of the x axis in this figure? we should either sort it alphabetically or by detection rate.}

\fi


\subsection{Submission History}
\label{sec:history}

\input{section/fig_2corr2}

One file could be submitted more than once to VirusTotal. 
Given a submission, we also study whether information for historical 
submissions of the same file influences detection rate for the current submission. 

\noindent{\textit{\underline{Historical submission number.}}}
We sort submissions for each file chronologically, 
and then calculate the correlation between detection rate and historical submission number for each submission. 
All historical submission numbers are rounded up to the nearest 5. 
How detection rate changes with historical submission number is shown in Figure~\ref{fig:hisnum}. 
The curve decreases from 0 to 10, increases from 10 to 65, decreases from 65 to 75, and increases after 75. 

\yiying{I'm completely confused about your explanation here.}
We think there are two factors influencing whether detection rate would increase or decrease.
One is the percentage of benign files submitted to VirusTotal, 
and with more benign files submitted, detection rate will decrease.   
The other one is the percentage of engines identifying the submitted malwares, 
and with more engines identifying the malware, detection rate will increase. 
In the two stages of detection rate decreasing, 
VirusTotal users stop submitting identified malwares, 
and the increase of percentage of benign files submitted to VirusTotal dominates. 
In the the two stages of detection rate increasing, 
more engines can identify submitted malwares, 
and the increase of percentage of engines identifying submitted malwares dominates. 

\noindent{\textit{\underline{Historical source ID.}}}
One file could be submitted by one source ID multiple times, 
and could also submitted by different source IDs. 
We study correlation between the number of historical source IDs and detection rate. 
Each number of historical source IDs is rounded up to nearest 5. 
\yiying{Can you not round to 5? the point at 15 is strange and you don't have a good explanation. maybe if we split into original interval (i.e., 1 instead of rounding), we can find some possible explanation?}
Average detection rate and confidence interval for each number of historical source IDs are shown in Figure~\ref{fig:hisid}. 
Confidence intervals are invisible before 80. 
Detection rate is higher for historical source IDs less than 15, compared with historical source IDs more than 15.
The number of historical source IDs reflects the popularity of a submitted file.
Figure~\ref{fig:hisid} shows that when popularity of a file larger than a certain threshold, like 15 source IDs, 
it is unrelated to detection rate and how malicious of the file viewed by anti-virus engines. 

{\bf Observation 5:} 
{\em }

\if 0
\noindent{\textit{\underline{Historical source country.}}}
One file could also be submitted from different countries. 
The number of historical source countries also reflect the popularity of a submitted file. 
The correlation between detection rate and the number of historical source countries in 
Figure~\ref{fig:hiscountry} shows similar trend as the correlation between detection rate 
and the number of historical source IDs in Figure~\ref{fig:hiscountry}. 

Figure~\ref{fig:hisnum}, Figure~\ref{fig:hisid}, and Figure~\ref{fig:hiscountry} show that 
when historical numbers fall into certain range, they are correlated with detection rate. 
\fi

\subsection{Reputation of Source ID}
\label{sec:reputation}

Previous work~\cite{GuoICSE2010} reported correlation between bug reporter’s reputation and the likelihood for the bug being fixed. 
We also observe correlation between the reputation of source ID and submission’s detection rate. 

%\theoremstyle{definition}
\begin{definition}{Reputation:}
Given a submission $S$ with source ID $N$, 
we define the reputation of $N$ when conducting the submission $S$ as the average detection rate for all submissions conducted by $N$ before $S$. 
If $N$ did not make any submission before, we define the reputation to be $-1$. 
\end{definition}

For around 14\% PE submissions, VirusTotal fails to provide source ID information. 
We filter out these submissions, when computing reputation.
All other PE submissions are conducted by 613 thousand source IDs. 
66\% source IDs only conduct submission once. 
XXX
We filter source IDs conducting more than 1 million PE submissions in our data set, 
because we think these are anti-virus vendors routinely test their products. 

When calculating reputation, we sort all submissions from the same source ID chronologically, 
and calculate reputation for each source id when conducting each submission. 
We round up each calculated reputation to nearest 0.05. 
We group submissions based on source ids' reputation when conducting submissions, 
and we plot average detection rate and 95\% confidence interval for each group in Figure~\ref{fig:idreputation}. 
Except the point with reputation 1, all other confidence intervals are invisible.  

As shown in Figure~\ref{fig:idreputation}, 
there is a rough increase for detection rate as the increase of source ID's reputation, 
with the exception for the point with reputation -1 and the point with reputation 1. 
It is interesting to observe that first submissions conducted by different source IDs have higher 
detection rate than submissions conducted by IDs with reputation 0, 
and it is difficult for source IDs with highest reputation to always submit files detected by all engines. 
Correlation between source ID's reputation and detection rate indicates 
that it is feasible to use source IDs' submission history to predict their future submissions.

{\bf Observation 6:} 
{\em }

\subsection{Discussion}

\noindent{\textit{\underline{How to use our data?}}}
As we discussed from Section~\ref{sec:reputation} to Section~\ref{sec:country}, 
source ID reputation, historical number in certain range, file size, 
and source country are highly correlated with detection rate. 
Future work could train a regression model to combine all these factors together and 
predict how many engines could detect a malware or how likely a file is a malware. 
Using the regression model or our studying results alone, 
security experts can prioritize malwares and focus their efforts on malwares which are more malicious. 
Anti-virus vendors could inspect results which are variant from our studying results 
to identify possible false positives or false negatives in their products. 

\noindent{\textit{\underline{Limitations of our study.}}}
As we discussed in Section~\ref{sec:meth}, our study is binded with our methodology.
We do not have any data before 05/07/2016, 
which may cause some reputation and historical numbers 
we calculate different from their real values. 
However, we think we can tolerate this error, 
since we conduct our study in a relatively long time range and in a large scale. 
In the future, we could design our reputation and historical metrics based on a tunable time windows, and investigate whether correlations still exist.   
